{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Comparison between Chamber of Deputies CEAP datasets 1.0 and 2.0\n",
    "\n",
    "This notebook compares the old Chamber's CEAP dataset (the huge XML files) with the new one (CSV by year). The main objective of this comparison is to show we didn't lose any data on the migration from the 1.0 to the much more efficient 2.0 version of the data. This validates changes to serenata-toolbox so we can ditch 1.0 datasets for good and be prepare to their extinction by the Chamber's Open Data team.\n",
    "\n",
    "Let's begin by loading both old and new datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.set_option('max_columns', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading 2017-05-21-reimbursements.old.xz: 100%|██████████| 34.0M/34.0M [02:51<00:00, 198Kb/s]\n",
      "Downloading 2017-05-21-reimbursements.new.xz: 100%|██████████| 34.1M/34.1M [02:22<00:00, 240Kb/s]\n"
     ]
    }
   ],
   "source": [
    "from serenata_toolbox.datasets import Datasets\n",
    "\n",
    "datasets = Datasets('../data')\n",
    "datasets.downloader.download('2017-05-21-reimbursements.old.xz')\n",
    "datasets.downloader.download('2017-05-21-reimbursements.new.xz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_dataset = pd.read_csv('../data/2017-05-21-reimbursements.old.xz',\n",
    "                        compression='xz',\n",
    "                        low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dataset = pd.read_csv('../data/2017-05-21-reimbursements.new.xz',\n",
    "                        compression='xz',\n",
    "                        low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to check if both datasets have the same columns, even in they are in the same order:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True]\n"
     ]
    }
   ],
   "source": [
    "old_keys = old_dataset.keys()\n",
    "new_keys = new_dataset.keys()\n",
    "\n",
    "print(old_keys==new_keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also make sure they have the same types for all columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "year                          True\n",
       "applicant_id                  True\n",
       "document_id                   True\n",
       "reimbursement_value_total     True\n",
       "total_net_value               True\n",
       "reimbursement_numbers         True\n",
       "congressperson_name           True\n",
       "congressperson_id             True\n",
       "congressperson_document       True\n",
       "term                          True\n",
       "state                         True\n",
       "party                         True\n",
       "term_id                       True\n",
       "subquota_number               True\n",
       "subquota_description          True\n",
       "subquota_group_id             True\n",
       "subquota_group_description    True\n",
       "supplier                      True\n",
       "cnpj_cpf                      True\n",
       "document_number               True\n",
       "document_type                 True\n",
       "issue_date                    True\n",
       "document_value                True\n",
       "remark_value                  True\n",
       "net_values                    True\n",
       "month                         True\n",
       "installment                   True\n",
       "passenger                     True\n",
       "leg_of_the_trip               True\n",
       "batch_number                  True\n",
       "reimbursement_values          True\n",
       "dtype: bool"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_dataset.dtypes == old_dataset.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can take a slice of the datasets by year and compare their sizes. We also remove the current year, because this ongoing registry seems to have different update pace between versions, so it makes no sense comparing them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "year: 2009 old: 171942 new: 171942 diff: 0\n",
      "year: 2010 old: 204299 new: 204299 diff: 0\n",
      "year: 2011 old: 213379 new: 213379 diff: 0\n",
      "year: 2012 old: 197019 new: 197019 diff: 0\n",
      "year: 2013 old: 194157 new: 194157 diff: 0\n",
      "year: 2014 old: 172144 new: 172144 diff: 0\n",
      "year: 2015 old: 208729 new: 208729 diff: 0\n",
      "year: 2016 old: 200943 new: 200942 diff: -1\n"
     ]
    }
   ],
   "source": [
    "old_dataset = old_dataset[old_dataset['year'] != 2017]\n",
    "new_dataset = new_dataset[new_dataset['year'] != 2017]\n",
    "\n",
    "for year in pd.unique(old_dataset['year']):\n",
    "    old_size = len(old_dataset[old_dataset['year']==year])\n",
    "    new_size = len(new_dataset[new_dataset['year']==year])\n",
    "    print('year: {} old: {} new: {} diff: {}'.format(year, old_size, new_size, new_size-old_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oddly enough, there is a single row missing in the new dataset. Let's find out which document is that and also make sure the exact document_ids are present in both datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extra documents found in old dataset: 1\n",
      "Extra documents found in new dataset: 0\n"
     ]
    }
   ],
   "source": [
    "new_docs = list(new_dataset['document_id'])\n",
    "old_docs = list(old_dataset['document_id'])\n",
    "\n",
    "old_extra = list(set(old_docs) - set(new_docs))\n",
    "print('Extra documents found in old dataset: {}'.format(len(old_extra)))\n",
    "\n",
    "new_extra = list(set(new_docs) - set(old_docs))\n",
    "print('Extra documents found in new dataset: {}'.format(len(new_extra)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So there is really only one inconsistency between datasets. A quick query can show us the culprit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>applicant_id</th>\n",
       "      <th>document_id</th>\n",
       "      <th>reimbursement_value_total</th>\n",
       "      <th>total_net_value</th>\n",
       "      <th>reimbursement_numbers</th>\n",
       "      <th>congressperson_name</th>\n",
       "      <th>congressperson_id</th>\n",
       "      <th>congressperson_document</th>\n",
       "      <th>term</th>\n",
       "      <th>state</th>\n",
       "      <th>party</th>\n",
       "      <th>term_id</th>\n",
       "      <th>subquota_number</th>\n",
       "      <th>subquota_description</th>\n",
       "      <th>subquota_group_id</th>\n",
       "      <th>subquota_group_description</th>\n",
       "      <th>supplier</th>\n",
       "      <th>cnpj_cpf</th>\n",
       "      <th>document_number</th>\n",
       "      <th>document_type</th>\n",
       "      <th>issue_date</th>\n",
       "      <th>document_value</th>\n",
       "      <th>remark_value</th>\n",
       "      <th>net_values</th>\n",
       "      <th>month</th>\n",
       "      <th>installment</th>\n",
       "      <th>passenger</th>\n",
       "      <th>leg_of_the_trip</th>\n",
       "      <th>batch_number</th>\n",
       "      <th>reimbursement_values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1560132</th>\n",
       "      <td>2016</td>\n",
       "      <td>831</td>\n",
       "      <td>6271581</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3051.3</td>\n",
       "      <td>5838</td>\n",
       "      <td>RUBENS BUENO</td>\n",
       "      <td>73466.0</td>\n",
       "      <td>460.0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>PR</td>\n",
       "      <td>PPS</td>\n",
       "      <td>55.0</td>\n",
       "      <td>137</td>\n",
       "      <td>Participation in course, talk or similar event</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>INTERNATIONAL FOUNDATION FOR ELECTORAL SYSTEMS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NS</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-11-06T00:00:00</td>\n",
       "      <td>3051.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3051.3</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1380250</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         year  applicant_id  document_id  reimbursement_value_total  \\\n",
       "1560132  2016           831      6271581                        NaN   \n",
       "\n",
       "         total_net_value reimbursement_numbers congressperson_name  \\\n",
       "1560132           3051.3                  5838        RUBENS BUENO   \n",
       "\n",
       "         congressperson_id  congressperson_document    term state party  \\\n",
       "1560132            73466.0                    460.0  2015.0    PR   PPS   \n",
       "\n",
       "         term_id  subquota_number  \\\n",
       "1560132     55.0              137   \n",
       "\n",
       "                                   subquota_description  subquota_group_id  \\\n",
       "1560132  Participation in course, talk or similar event                  0   \n",
       "\n",
       "        subquota_group_description  \\\n",
       "1560132                        NaN   \n",
       "\n",
       "                                               supplier  cnpj_cpf  \\\n",
       "1560132  INTERNATIONAL FOUNDATION FOR ELECTORAL SYSTEMS       NaN   \n",
       "\n",
       "        document_number  document_type           issue_date  document_value  \\\n",
       "1560132              NS              2  2016-11-06T00:00:00          3051.3   \n",
       "\n",
       "         remark_value  net_values  month  installment passenger  \\\n",
       "1560132           0.0      3051.3     11            0       NaN   \n",
       "\n",
       "        leg_of_the_trip  batch_number  reimbursement_values  \n",
       "1560132             NaN       1380250                   NaN  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_dataset[old_dataset['document_id'].isin(old_extra)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the CSV file for year 2016 in the 2.0 version of the data, this document_id 6271581 is really missing, so it's not a parse problem on our side. An email was sent to Camara's Open Data team so we can understand what is happening."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
